---

#STEP 1 - ADD DNS ENTRIES
- hosts: 127.0.0.1
  connection: local
  gather_facts: no
  vars_files:
    - environment_vars.yml
  roles:
    - role: dns-record
      dns_environment: '{{ environments[target_environment].dns_environment }}'
      start_ip: '{{ environments[target_environment].vm_start_ip }}'
      end_ip: '{{ environments[target_environment].vm_end_ip }}'
      server_name: '{{ server1_hostname }}'
      tags: [ 'create_dns_vm1' ]
    - role: dns-record
      dns_environment: '{{ environments[target_environment].dns_environment }}'
      start_ip: '{{ environments[target_environment].vm_start_ip }}'
      end_ip: '{{ environments[target_environment].vm_end_ip }}'
      server_name: '{{ server2_hostname }}'
      tags: [ 'create_dns_vm2' ]
    - role: dns-record
      dns_environment: '{{ environments[target_environment].dns_environment }}'
      start_ip: '{{ environments[target_environment].vip_start_ip }}'
      end_ip: '{{ environments[target_environment].vip_end_ip }}'
      server_name: '{{ common_name }}'
      tags: [ 'create_dns_vip' ]
  tags:
    - create_dns

#STEP 2 - GET THE IPs FROM THE ABOVE STEP, PUT IN VARS, THEN CREATE VMs, buy SSL cert, create VIP
- hosts: 127.0.0.1
  connection: local
  gather_facts: no
  vars_files:
    - environment_vars.yml
    - jboss_stack_provision_vault.yml
  pre_tasks:
    - name: get server1 ip
      command: dig @{{ environments[target_environment].dns_dig_server }} +short {{ server1_hostname }}
      register: server1_ip
      tags: [ 'create_vms', 'create_vm1', 'get_ips_dns' ]
    - name: get server2 ip
      command: dig @{{ environments[target_environment].dns_dig_server }} +short {{ server2_hostname }}
      register: server2_ip
      tags: [ 'create_vms', 'create_vm2', 'get_ips_dns' ]
    - name: get common_name ip
      command: dig @{{ environments[target_environment].dns_dig_server }} +short {{ common_name }}
      register: vip_ip
      tags: [ 'create_vip', 'get_ips_dns' ]
  roles:
    - role: vsphere-guest
      vm_name: '{{ server1_hostname }}'
      ip_addr: '{{ server1_ip.stdout }}'
      ip_mask: '{{ environments[target_environment].ip_mask }}'
      ip_gateway: '{{ environments[target_environment].ip_gateway }}'
      fqdn: '{{ server1_hostname }}'
      vm_memsize: '{{ vm_memsize }}'
      vm_numcpus: '{{ vm_numcpus }}'
      vsphere_environment: '{{ environments[target_environment].vsphere_environment }}'
      vcenter_username: '{{ vsphere_vault[vsphere_environment].username }}'
      vcenter_password: '{{ vsphere_vault[vsphere_environment].password }}'
      vcenter_template: '{{ environments[target_environment].vcenter_template }}'
      vcenter_resource_pool: '{{ environments[target_environment].vcenter_resource_pool }}'
      vcenter_cluster: '{{ environments[target_environment].vcenter_cluster }}'
      vcenter_hostname: '{{ environments[target_environment].vcenter_hostname }}'
      tags: [ 'create_vms', 'create_vm1' ]
    - role: vsphere-guest
      vm_name: '{{ server2_hostname }}'
      ip_addr: '{{ server2_ip.stdout }}'
      ip_mask: '{{ environments[target_environment].ip_mask }}'
      ip_gateway: '{{ environments[target_environment].ip_gateway }}'
      fqdn: '{{ server2_hostname }}'
      vm_memsize: '{{ vm_memsize }}'
      vm_numcpus: '{{ vm_numcpus }}'
      vsphere_environment: '{{ environments[target_environment].vsphere_environment }}'
      vcenter_username: '{{ vsphere_vault[vsphere_environment].username }}'
      vcenter_password: '{{ vsphere_vault[vsphere_environment].password }}'
      vcenter_template: '{{ environments[target_environment].vcenter_template }}'
      vcenter_resource_pool: '{{ environments[target_environment].vcenter_resource_pool }}'
      vcenter_cluster: '{{ environments[target_environment].vcenter_cluster }}'
      vcenter_hostname: '{{ environments[target_environment].vcenter_hostname }}'
      tags: [ 'create_vms', 'create_vm2' ]
    - role: ssl-cert-verisign
      when: ssl
      key_file: '{{ key_file }}'
      csr_file: '{{ csr_file }}'
      fqdn: '{{ common_name }}'
      ou: '{{ ou }}'
      challenge_phrase: '{{ challenge_phrase }}'
      cert_type: '{{ cert_type }}'
      server_type: '{{ server_type }}'
      validity_period: '{{ validity_period }}'
      cert_file: '{{ cert_file }}'
      first_name: '{{ first_name }}'
      last_name: '{{ last_name }}'
      email: '{{ email }}'
      tags: [ 'buy_ssl' ]
    - role: f5
      common_name_ip: '{{ vip_ip.stdout }}'
      s1_ip: '{{ server1_ip.stdout }}'
      s2_ip: '{{ server2_ip.stdout }}'
      f5_environment: '{{ environments[target_environment].f5_environment }}'
      tags: [ 'create_vip' ]

#STEP 3 - WAIT UNTIL THE GUESTS ARE FULLY ONLINE AND SSH IS LISTENING
- hosts: 127.0.0.1
  connection: local
  gather_facts: no
  tasks:
    - name: wait for server1
      wait_for: host='{{ server1_hostname }}' port=22 state=started
    - name: wait for server2
      wait_for: host='{{ server2_hostname }}' port=22 state=started
  tags:
    - wait_for_servers_to_be_up

#STEP 4 - ADD APP DISK
- hosts: newservers
  user: ansible
  sudo: True
  vars_files:
    - environment_vars.yml
  pre_tasks:
    - name: add_disk
      connection: local
      sudo: false
      shell: > 
        ENV='{{ environments[target_environment].vsphere_environment }}' 
        /home/ansible/ansible-dependencies/vsphere_guest_add_disk/vsphere_add_disk_to_guest.py 
        -n '{{ inventory_hostname }}' 
        -d '{{ item.value.disk_size_gb }}' 
        -s '{{ environments[target_environment].vsphere_datastore }}'
      with_dict: '{{ disks }}'
    - name: create_vg
      lvg:
        vg: '{{ item.value.vg_name }}'
        pvs: '{{ item.value.device }}'
      with_dict: '{{ disks }}'
  tasks:
    - name: create lv in the vg
      lvol: 
        vg: '{{ item.value.vg }}'
        lv: '{{ item.value.lv_name }}'
        size: '{{ item.value.lv_size }}'
      with_dict: '{{ lvols }}'
    - name: create filesystem on the new lv
      filesystem:
        fstype: '{{ item.value.fs_type }}'
        dev: /dev/{{ item.value.vg }}/{{ item.value.lv_name }}
      with_dict: '{{ lvols }}'
    - name: mount the new filesystem and add to fstab
      mount:
        name: '{{ item.value.mount_point }}'
        src: /dev/{{ item.value.vg }}/{{ item.value.lv_name }}
        fstype: '{{ item.value.fs_type }}'
        state: mounted
        dump: 1
        passno: 2
      with_dict: '{{ lvols }}'
  tags:
    - add_disk

#STEP 5 - Setup user accounts and groups on new VMs
- hosts: newservers
  user: ansible
  sudo: True
  tasks:
    - name: Create groups
      group:
        name: '{{ item.value.groupname }}'
        gid: '{{ item.value.gid }}'
        state: present
      with_dict: '{{ user_groups }}'
    - name: Create core services accounts
      user: 
        name: '{{ item.value.username }}'
        comment: '{{ item.value.gecos }}' 
        home: '{{ item.value.home }}'
        group: '{{ item.value.group }}' 
        shell: '{{ item.value.shell }}' 
        uid: '{{ item.value.uid }}' 
        groups: '{{ item.value.groups }}' 
        password: '{{ item.value.passwordcrypt }}' 
        update_password: on_create 
        state: present
      with_dict: '{{ user_accounts }}'
    - name: Grant Core Services team (edmcore group) sudo access
      lineinfile: "dest=/etc/sudoers line='%edmcor ALL=(ALL) NOPASSWD: /bin/su - {{ jboss_user_name }}, /etc/init.d/{{ app_acct_name }}, /bin/su - {{ app_acct_name }}' insertafter='^ansible ' state=present"
    - name: Grant AppDev team (appdev group) sudo access only in non-prod environments
      lineinfile: "dest=/etc/sudoers line='%appdev ALL=(ALL) NOPASSWD: /bin/su - {{ app_acct_name }}' insertafter='^ansible ' state=present"
      when: target_environment != "prod"
  tags:
    - create_users_groups

#STEP 6 - INSTALL OS LEVEL PKGS
- hosts: newservers
  user: ansible
  sudo: True
  roles:
    - eracent-client
    - legato-networker
    - opsware-agent
  tags:
    - apply_os_roles

#STEP 7 - INSTALL JBOSS ON THE NEW VMs
- hosts: newservers
  user: ansible
  vars_files:
    - jboss_stack_provision_vault.yml
  sudo: True
  roles:
    - jboss
  tags:
    - apply_jboss_role

#STEP 8 - SEND NOTIFICATIONS TO ALL INTERESTED PARTIES
- hosts: newservers
  become: True
  become_user: root
  vars_files:
    - environment_vars.yml
  tasks:
    - name: Get VIP IP address to include in notification
      delegate_to: 127.0.0.1
      run_once: true
      become: False
      command: dig @{{ environments[target_environment].dns_dig_server }} +short {{ common_name }}
      register: vip_ip
      ignore_errors: True
    - name: Send email to Asset Mgmt with new asset info
      delegate_to: 127.0.0.1
      run_once: true
      become: False
      mail:
        from: '{{ notify_from }}'
        to: '{{ notify_to }}'
        subject: '{{ notify_subject }}'
        body: |
          The following new assets (RHEL VMs running JBoss with an F5 bigIP VIP) were provisioned automatically via Ansible for EIT Core Services.

          ServiceNow REQ: {{ request_number }}

          Hosts:

          {% for host in groups['newservers'] %}

          HOSTNAME: {{ host }}
          IPADDR: {{ hostvars[host].ansible_default_ipv4.address }}
          SERIAL_NUMBER: {{ hostvars[host].ansible_product_serial }}

          {% endfor %}

          {% if vip_ip.stdout != "" %}
          VIP DNS Name: {{ common_name }}
          VIP IPADDR: {{ vip_ip.stdout }}
          {% else %}
          NOTE: VIP not created at this time.  Another notification will be sent when VIP is created.
          {% endif %}

          Application Name: {{ cmdb_appname }}
          Business Owner: {{ cmdb_business_owner }}
          Business Owner Dept: {{ cmdb_business_owner_dept }}
          Tech Owner: {{ cmdb_tech_owner }}
          Tech Owner Dept: {{ cmdb_tech_owner_dept }}

          The following needs to be done:
          1.) Asset Mgmt Team needs to update asset data in CMDB to include business info.
          2.) Network team needs to add Load Balancer VIP information to VIP inventory.
          3.) SysAdmin team needs to be aware of these new servers that were provisioned.
          4.) Backup team needs to add these new servers to backups.
          5.) Monitoring team needs to add these new servers to monitoring.
  tags:
    - send_notifications

